{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependecny which provides us with the Training data set of the predicting the house\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "#Now first let's have a look at all the feautures which are there for input example in boston\n",
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let also see, what each feauture represents\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = boston.data\n",
    "Y = boston.target\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(type(X),type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2    3      4      5     6       7    8      9    10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's look at the data first. Looking data in the form of table will help us understand it better. So let's use pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df.head()\n",
    "#Therefore clearly in total we have 13 features for each input example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,) (13,)\n",
      "[3.61352356e+00 1.13636364e+01 1.11367787e+01 6.91699605e-02\n",
      " 5.54695059e-01 6.28463439e+00 6.85749012e+01 3.79504269e+00\n",
      " 9.54940711e+00 4.08237154e+02 1.84555336e+01 3.56674032e+02\n",
      " 1.26530632e+01]\n",
      "[8.59304135e+00 2.32993957e+01 6.85357058e+00 2.53742935e-01\n",
      " 1.15763115e-01 7.01922514e-01 2.81210326e+01 2.10362836e+00\n",
      " 8.69865112e+00 1.68370495e+02 2.16280519e+00 9.12046075e+01\n",
      " 7.13400164e+00]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clearly data is not normalised. Therefore first normalise the data. Then only use it. Note- Obviously we will normalise\n",
    "it feature wise. Therefore calculate mean and standard deviation columm wise\n",
    "\"\"\"\n",
    "u = np.mean(X,axis = 0)\n",
    "std = np.std(X,axis = 0)\n",
    "\n",
    "print(u.shape,std.shape)\n",
    "print(u)\n",
    "print(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising the data\n",
    "X = (X - u)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept to normalise the data done above is discussed in extras in numpy\n",
    "<img src='Explaination.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression on Multiple Features Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "#First Modifying the input matrix X to add the first column Xo\n",
    "ones = np.ones((X.shape[0],1))\n",
    "print(ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((ones,X),axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.417044</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>0.207096</td>\n",
       "      <td>-0.351157</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.410571</td>\n",
       "      <td>-1.043322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410243</td>\n",
       "      <td>0.048772</td>\n",
       "      <td>-0.476654</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.265154</td>\n",
       "      <td>-0.388411</td>\n",
       "      <td>-0.070229</td>\n",
       "      <td>0.839244</td>\n",
       "      <td>-0.523001</td>\n",
       "      <td>-0.577519</td>\n",
       "      <td>-1.505237</td>\n",
       "      <td>0.426798</td>\n",
       "      <td>-0.031268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7  \\\n",
       "0  1.0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1  1.0 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2  1.0 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3  1.0 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4  1.0 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "5  1.0 -0.417044 -0.487722 -1.306878 -0.272599 -0.835284  0.207096 -0.351157   \n",
       "6  1.0 -0.410243  0.048772 -0.476654 -0.272599 -0.265154 -0.388411 -0.070229   \n",
       "\n",
       "          8         9        10        11        12        13  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n",
       "5  1.077737 -0.752922 -1.106115  0.113032  0.410571 -1.043322  \n",
       "6  0.839244 -0.523001 -0.577519 -1.505237  0.426798 -0.031268  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should first confirm if 1 is added as 1st column or not\n",
    "pd.DataFrame(X).head(n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Avoid loops in the implemenation, except gradient descent main loop.Use numpy functions like np.sum(), np.dot() \n",
    "which are quite fast and already optimised\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X,theta):\n",
    "    #Initially X is (506,14) and theta is (14,). Note - Here we don't need to transpose it as it is already present \n",
    "    #in the form of vector (which is seen vertically only)\n",
    "    \n",
    "    #Therefore it will calculate the multplicative product, even if we pass single X\n",
    "    mulitplicative_product =  np.dot(X,theta) #Therefore now it's shape will be (506,)\n",
    "    return mulitplicative_product\n",
    "\n",
    "\n",
    "def error(X,Y,theta):\n",
    "    #Shape of X is (506,14), Y is (506,) and theta is (14,)\n",
    "    predictedYs = hypothesis(X,theta) #Shape - (506,)\n",
    "    e = np.sum((Y-predictedYs)**2) #Here first matrix element wise subtraction will take place, then through \n",
    "    #broadcasting for each term square will be calculated\n",
    "    return e/X.shape[0]\n",
    "    \n",
    "    \n",
    "def gradient(X,Y,theta):\n",
    "    predictedYs = hypothesis(X,theta) #Shape is (506,)\n",
    "    X_Transpose = np.transpose(X)  #Shape is (14,506)\n",
    "    grad = np.dot(X_Transpose,(predictedYs-Y)) #Shape is (14,)\n",
    "    return grad/X.shape[0]  \n",
    "\n",
    "\n",
    "def applying_gradient_descentRul(X,Y,learning_rate = 0.1,max_iterations = 500):\n",
    "    \n",
    "    #Initializing initially all thetas as 0. They would be gradually updated using update rule\n",
    "    theta = np.zeros(( X.shape[1],))\n",
    "    \n",
    "    error_list = []\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        e = error(X,Y,theta)\n",
    "        error_list.append(e)\n",
    "        \n",
    "        #Finding the new gradients at this update \n",
    "        grads = gradient(X,Y,theta)\n",
    "        theta = theta - learning_rate*grads\n",
    "        \n",
    "    return theta,error_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken is  0.04562211036682129\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let also calculate the time it takes to calcuate theta for this --\n",
    "import time\n",
    "\n",
    "start  = time.time()\n",
    "theta,error_list = applying_gradient_descentRul(X,Y)\n",
    "end = time.time()\n",
    "print(\"Time Taken is \",end-start)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(error_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the R2 Score for above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.25328063e+01 -9.21661049e-01  1.07018508e+00  1.05792229e-01\n",
      "  6.86754753e-01 -2.05015324e+00  2.68068988e+00  1.39987663e-02\n",
      " -3.10628221e+00  2.57363827e+00 -1.97626899e+00 -2.05723354e+00\n",
      "  8.48669383e-01 -3.74020167e+00]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.06279773949944\n"
     ]
    }
   ],
   "source": [
    "def r2_score(Y,Y_):\n",
    "    numerator = np.sum((Y-Y_)**2)\n",
    "    denominator = np.sum((Y-Y.mean())**2)\n",
    "    score = 1 -(numerator/denominator)\n",
    "    return score*100\n",
    "    \n",
    "print(r2_score(Y,hypothesis(X,theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Accuracy is coming very less, therefore there might be some other way too not necessarily linear with which we \n",
    "can approximate this F(X) , so that it is more closer to actual Y. Maybe F(X) can be approximated by some other \n",
    "function which may be quadratic or any other general function. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
